{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTheoTvKyKTeDJTATkH+77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aidin12/gpt4-smart-chatbot/blob/main/Scraper_GPT_Small_Business_Chatbot_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='DeepPink'> Building Your Own Smart Chatbot: Engaging Customer Service with GPT-4 and OpenAI API </font>\n",
        "#Learning Objectives:  \n",
        "<font color='lime'>\n",
        "\n",
        "1.  Learn how to use large language models (LLMs) to create a custom chatbot for a small business.  \n",
        "2. Understand how to extract and fine-tune a GPT-based model using business-specific data.  \n",
        "3. Learn about the benefits of LLM-based chatbots compared to rule-based approaches.   </font> \\\\\n",
        "\n",
        "# Technologies Used:\n",
        "<font color='DeepSkyBlue'>  \n",
        " - Python for general programming.\n",
        " - OpenAI API for accessing GPT-4 for language generation.\n",
        " - Pandas for data handling.\n",
        " - Flask for creating a lightweight web API.\n",
        " - Google Colab as the working environment.\n",
        " - Torch to check for GPU availability and optimize performance.\n",
        " </font>"
      ],
      "metadata": {
        "id": "vt_QMVJjCoqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muEUiLaQCiw5",
        "outputId": "556a94b2-1956-41f5-9e67-696a2f91582f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (3.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "# Colab requirements: Install necessary libraries\n",
        "!pip install flask\n",
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU (CUDA) is available for faster computations; otherwise, use the CPU\n",
        "# Using GPU is recommended for faster generation as Stable Diffusion is computationally intensive.\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"You're using: {gpu_name}\")\n",
        "else:\n",
        "    print(\"No GPU detected.\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv07q_4sHmR0",
        "outputId": "da133370-4472-4d68-d439-132675d1701e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You're using: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from flask import Flask, request, jsonify\n",
        "import re"
      ],
      "metadata": {
        "id": "jmwg0Dy2HmWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Collection\n",
        "Using a web scraper to gather product data, delivery info, and other information from the CBD-UK website."
      ],
      "metadata": {
        "id": "EyB1ZabQJnaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access storage\n",
        "from google.colab import drive\n",
        "# Mount the drive to access Google Drive files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0X6F3kOHmbq",
        "outputId": "fda5b04a-f69a-47fe-897d-65041059d734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder in Google Drive to save the CSV file\n",
        "import os\n",
        "# Create the folder named 'CBD' in Google Drive if it doesn't already exist\n",
        "os.makedirs('/content/drive/My Drive/CBD', exist_ok=True)"
      ],
      "metadata": {
        "id": "eKHKB1QCJ6E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "ScpKKMKxJ6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Scrape Book Information from Books to Scrape Website\n",
        "def scrape_books_to_scrape(url):\n",
        "    \"\"\"\n",
        "    Scrapes book title, stock status, and price from the Books to Scrape website.\n",
        "    Args:\n",
        "    - url (str): The URL of the website to scrape.\n",
        "\n",
        "    Returns:\n",
        "    - List of dictionaries containing book data.\n",
        "    \"\"\"\n",
        "    # Send a request to the website to get the content\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to retrieve the webpage.\")\n",
        "        return []\n",
        "\n",
        "    # Parse the website's content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract book data\n",
        "    books = []\n",
        "\n",
        "    # Locate all book containers within the page using appropriate classes\n",
        "    book_containers = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    if not book_containers:\n",
        "        print(\"No book containers found. Please check the HTML structure or the URL.\")\n",
        "    else:\n",
        "        for book_container in book_containers:\n",
        "            # Extract book title\n",
        "            book_title = book_container.h3.a['title']\n",
        "\n",
        "            # Extract stock information\n",
        "            stock_tag = book_container.find('p', class_='instock availability')\n",
        "            in_stock = 'No'\n",
        "            if stock_tag:\n",
        "                if 'in stock' in stock_tag.text.lower():\n",
        "                    in_stock = 'Yes'\n",
        "\n",
        "            # Extract price information\n",
        "            price_tag = book_container.find('p', class_='price_color')\n",
        "            price = price_tag.text.strip() if price_tag else 'No price available'\n",
        "\n",
        "            # Append book details to the list\n",
        "            books.append({\n",
        "                'Title': book_title,\n",
        "                'InStock': in_stock,\n",
        "                'Price': price\n",
        "            })\n",
        "\n",
        "    return books\n",
        "\n",
        "# Define the URL of the Books to Scrape website\n",
        "url = \"http://books.toscrape.com/\"\n",
        "\n",
        "# Scrape the book data\n",
        "book_data = scrape_books_to_scrape(url)\n",
        "\n",
        "# Step 2: Save the data to a CSV file on Google Drive\n",
        "# Mount Google Drive to access storage\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a folder in Google Drive to save the CSV file\n",
        "os.makedirs('/content/drive/My Drive/BooksToScrape', exist_ok=True)\n",
        "\n",
        "# Convert the scraped book data to a DataFrame\n",
        "books_df = pd.DataFrame(book_data)\n",
        "\n",
        "# Print a sample of the scraped book data\n",
        "print(\"Sample of scraped book data:\")\n",
        "print(books_df.head())\n",
        "\n",
        "# Save the DataFrame to a CSV file in the created folder in Google Drive\n",
        "csv_file_path = '/content/drive/My Drive/BooksToScrape/books_to_scrape_data.csv'\n",
        "if not books_df.empty:\n",
        "    books_df.to_csv(csv_file_path, index=False)\n",
        "    print(f\"Data saved successfully to {csv_file_path}\")\n",
        "else:\n",
        "    print(\"No data scraped. CSV file not saved.\")\n",
        "\n",
        "# Step 3: Read the data from CSV and print\n",
        "try:\n",
        "    loaded_books_df = pd.read_csv(csv_file_path)\n",
        "    print(\"Loaded book data from CSV:\")\n",
        "    print(loaded_books_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {csv_file_path}. Please check the file path and try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMK3zjfrr6V8",
        "outputId": "31255262-67b5-431e-b6d0-fa9abfedc6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Sample of scraped book data:\n",
            "                                   Title InStock   Price\n",
            "0                   A Light in the Attic     Yes  £51.77\n",
            "1                     Tipping the Velvet     Yes  £53.74\n",
            "2                             Soumission     Yes  £50.10\n",
            "3                          Sharp Objects     Yes  £47.82\n",
            "4  Sapiens: A Brief History of Humankind     Yes  £54.23\n",
            "Data saved successfully to /content/drive/My Drive/BooksToScrape/books_to_scrape_data.csv\n",
            "Loaded book data from CSV:\n",
            "                                   Title InStock   Price\n",
            "0                   A Light in the Attic     Yes  £51.77\n",
            "1                     Tipping the Velvet     Yes  £53.74\n",
            "2                             Soumission     Yes  £50.10\n",
            "3                          Sharp Objects     Yes  £47.82\n",
            "4  Sapiens: A Brief History of Humankind     Yes  £54.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-hAr7SxsDk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yphudDJ9sDsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}